\chapter{Операционная модель памяти C/C++11} \label{sec:opc11}
В главе описана операционная модель памяти C/C++11 \cite{Podkopaev-al:CoRR16}, или \OpCpp,
и реализованный интерпретатор для неё \app{TODO: \url{}}.
Сама модель представлена как семейство аспектов, каждый из которых описывает некоторую особенность
изначальной модели C/C++11 \cite{Batty-al:POPL11}.
Такое представление позволяет упрощать модель для задач, в которых рассматривается только подмножество
языка модели C/C++11.
Также, поскольку некоторые особенности оригинальной модели, такие как поддержка секвенциализации (см. раздел \ref{sec:opc11:join}),
неоднозначны, аспектное представление позволяет настраивать интерпретатор под интересующий вариант семантики.

Ключевыми понятиями в модели являются \emph{фронты} и \emph{операционные буферы}.
Фронты используются для представления осведомленности потоков о текущем состоянии общей памяти,
тогда как операционные буферы позволяют откладывать исполнение инструкций и
производить спекулятивные вычисления.

%% Операционное представление различных аспектов оригинальной модели памяти C/C++11 \cite{Batty-al:POPL11}
%% базируется на комбинации двух основных идей: \emph{фронтов} и \emph{операционных буферов}.

Описание модели структурировано следующим образом.
В разделе \ref{sec:opc11:base} рассматриваются базовые концепции модели на нескольких примерах,
которые требуются для представления исполнения расслабленных инструкций, приобретающих чтений и
высвобождающих записей.
Далее в разделе \ref{sec:opc11:fullmodel} рассматриваются части модели, которые описывают
поведение $\sco$-инструкций, неатомарных обращений к памяти, потребляющих чтений, а также
высвобождающих цепочек (release sequences).
\app{TODO}

\section{Основные концепции модели}
\label{sec:opc11:base}
Модель памяти $\OpCpp$ задана операционным способом, а, значит, существует
некоторая абстрактная машина, связанная с моделью, которая исполняет программы
по шагам. Далее мы будем использовать термин \emph{машина} $\OpCpp$ для её обозначения.

\subsection{Память и базовый фронт}
Состояние машины $\OpCpp$ включается в себя множество сообщений, которое называется 
\emph{памятью}. Сообщение --- это тройка из локации, значения и \emph{метки времени} (timestamp).
Метки времени являются натуральными числами и используются для упорядочивания сообщений, которые связаны с одной и той же локацией.
Такой порядок аналогичен отношению $\lMO$ в аксиоматической модели C/C++11 \cite{Batty-al:POPL11}.

Рассмотрим машину $\OpCpp$ на примере исполнения следующей программы.
\begin{equation*}
\tag{MP-rlx-2}
\begin{tabular}{c}
  $\writeInstParam{\rlx}{x}{0}; \writeInstParam{\rlx}{y}{0};$ \\
\begin{tabular}{L || L}
  \writeInstParam{\rlx}{x}{1}; & \readInstParam{\rlx}{a}{y}; \\
  \writeInstParam{\rlx}{y}{1}  & \readInstParam{\rlx}{b}{x}; \\
                               & \readInstParam{\rlx}{c}{x}\\
\end{tabular}
\end{tabular}
\end{equation*}
Это очередная вариация программы ${\rm MP}$, в которой во второй поток было добавлено дополнительное
чтение из локации $x$.

После исполнения первых двух инструкций программы
($\writeInstParam{\rlx}{x}{0}; \writeInstParam{\rlx}{y}{0}$) память машины будет содержать два сообщения:
\[
M = \{\angled{x:0@\tstamp{0}}, \angled{y:0@\tstamp{0}}\},
\]
где $\tstamp{0}$ -- метка времени.
После того, как левый поток закончит своё исполнение, в памяти будет четыре сообщения:
\[
M = \{\angled{x:0@\tstamp{0}}, \angled{y:0@\tstamp{0}},
      \angled{y:1@\tstamp{1}},\angled{x:1@\tstamp{1}}\}.
\]

Заметим, что в оригинальной модели C/C++11 \cite{Batty-al:POPL11} у рассматриваемой программы есть сценарий поведения
с результатом $[a = 1, b = 0, c = 0]$.
Для того, чтобы разрешить результат $[a = 1, b = 0, c = 0]$, потоки машины $\OpCpp$ имеют право при чтении выбирать из памяти
сообщение не с самым большой меткой времени (как этого требовала бы абстрактная машина, представляющая модель SC), т.е.
не самую последнюю запись в локацию.
Так, после завершения исполнения левого потока, правый поток может сначала прочитать сообщение $\angled{y:1@\tstamp{1}}$,
присвоив в регистр $a$ значение $1$, а после --- два раза из старого сообщения $\angled{x:0@\tstamp{0}}$,
получив $b = c = 0$.

В то же время модель C/C++11 запрещает сценарий поведения $[a = 1, b = 1, c = 0]$, поскольку гарантирует, что если поток
``увидел'' более новую запись в локацию, в данном случае сообщение $\angled{x:1@\tstamp{1}}$,
то более он не может прочитать более старое, с точки зрения отношения $\lMO$, сообщение.
Для того, чтобы поддержать данное ограничение, в модели $\OpCpp$ у каждого потока есть т.н. \emph{базовый фронт}.
Базовый фронт --- это частичная функция, которая по локации возвращает максимальную метку времени связанного с локацией сообщения, о
котором ``осведомлен'' поток.
Рассмотрим действие базового фронта на примере сценария поведения программы ${\rm MP\text{-}rlx\text{-}2}$,
который приводит к результату $[a = 1, b = 1, c = \_]$.

Так, после того, как поток читает или записывает сообщение в локацию $\loc$ с меткой времени $\tau$, он обновляет
свой базовый фронт по этой локации до $\tau$ и более не может читать $\loc$-сообщения с меньшей меткой.

Изначально в системе один поток $T0$ с пустым базовым фронтом.
После исполнения первых двух инструкций программы
($\writeInstParam{\rlx}{x}{0}; \writeInstParam{\rlx}{y}{0}$) базовый фронт потока, $T0.\Rcur$, будет указывать на
соответствующие сообщения из памяти:
\[
T0.\Rcur = [x@\tstamp{0}, y@\tstamp{0}]
\]
Далее машина стартует два потока, $T1$ и $T2$, базовые фронты которых будут равняться $T0.\Rcur$.
\[
T1.\Rcur = [x@\tstamp{0}, y@\tstamp{0}] \quad T2.\Rcur = [x@\tstamp{0}, y@\tstamp{0}]
\]
Далее, исполняются инструкции (левого) потока $T1$ и память содержит два новых сообщения,
а базовый фронт потока $T1$ увеличивается до $\tstamp{1}$ по обоим локациям,
т.к. поток, сделавший запись, естественным образом осведомлен о ней.
\[
\begin{array}{l}
T1.\Rcur = [\graybox{x@\tstamp{1}}, \graybox{y@\tstamp{1}}] \quad T2.\Rcur = [x@\tstamp{0}, y@\tstamp{0}]
\end{array}
\]
После этого (правый) поток $T2$ может прочитать новое сообщение в локацию $y$, присвоив $1$ в регистр $a$
и обновив свой фронт по локации $y$ до $\tstamp{1}$.
\[
\begin{array}{l}
T1.\Rcur = [x@\tstamp{1}, y@\tstamp{1}] \quad T2.\Rcur = [x@\tstamp{0}, \graybox{y@\tstamp{1}}]
\end{array}
\]
Т.к. базовый фронт потока $T2$ по локации $x$ равен $\tstamp{0}$, т.е. поток ещё не осведомлён о новой записи в $x$,
поток может прочитать либо сообщение $\angled{x:0@\tstamp{0}}$, либо сообщение $\angled{x:1@\tstamp{1}}$.
Для того, чтобы $b$ равнялось $1$, поток $T2$ должен прочитать из более нового сообщения, что обновит его
базовый фронт по локации $x$.
\[
\begin{array}{l}
T1.\Rcur = [x@\tstamp{1}, y@\tstamp{1}] \quad T2.\Rcur = [\graybox{x@\tstamp{1}}, y@\tstamp{1}]
\end{array}
\]
После этого потоку $T2$ остаётся только выполнить последнее чтение ($\readInstParam{\rlx}{c}{x}$),
и поскольку его базовый фронт по локации $x$ равен $\tstamp{1}$, то он может прочитать только
из нового сообщения в локацию $x$ ($\angled{x:1@\tstamp{1}}$).
Таким образом модель $\OpCpp$ запрещает результат $[a = 1, b = 1, c = 0]$.

%% Для рассматриваемой программы модель $\OpCpp$ должна разрешать сценарий поведения с результатом $[a = 1, b = 0, c = 0]$,
%% т.к. такой результат разрешает оригинальная модель C/C++11 \cite{Batty-al:POPL11}.
%% Рассмотрим сценарий поведения машины $\OpCpp$, который приводит к нему.

\subsection{Синхронизация потоков}
Рассмотрим программу ${\rm MP\text{-}rel\text{-}acq}$, которую мы уже обсуждали в главе \ref{sec:overview}.
\begin{equation*}
  \tag{MP-rel-acq}
\begin{tabular}{c}
  $\writeInstParam{\rlx}{x}{0}; \writeInstParam{\rlx}{y}{0};$ \\
\begin{tabular}{L || L}
  \writeInstParam{\rlx}{x}{1}; & \readInstParam{\acq}{a}{y}; \\
  \writeInstParam{\rel}{y}{1} & \readInstParam{\rlx}{b}{x}\\
\end{tabular}
\end{tabular}
\end{equation*}
Результат $[a = 1, b = 0]$ запрещён в C/C++11 MM для этой программы, т.к. если $a = 1$, то между потоками произошла
синхронизация (в соответствующем графе есть ребро отношения $\lSW$),
и перед выполнением $\readInstParam{\rlx}{b}{x}$ правый поток должен быть осведомлен
о записи $\writeInstParam{\rlx}{x}{1}$.

Для того, чтобы представить такую синхронизацию, у каждого сообщения машины $\OpCpp$
есть четвертая дополнительная компонента --- \emph{фронт сообщения}.
Фронт сообщения $m$ хранит информацию о сообщениях, о которых станет осведомлен
поток, который выполнит приобретающее ($\acq$) чтение сообщения $m$.
Если поток $T$ выполняет высвобождающую ($\rel$) запись, то фронтом сообщения,
которое будет добавлено в память как результат исполнения записи, будет базовый
фронт потока $T$ на момент выполнения записи.
Расслабленные ($\rlx$) записи также помещают некоторый фронт в соответствующие сообщения,
но по более сложным правилам, которые будут описаны в разделе \ref{sec:opc11:fullmodel}.

Рассмотрим сценарий поведения ${\rm MP\text{-}rel\text{-}acq}$, в котором $a = 1$, т.е. происходит синхронизация.
После того, как выполнены две инициализирующие записи и запущены два потока, память и базовые фронты потоков
выглядят следующим образом:
\[
\begin{array}{l}
M = \{\angled{x:0@\tstamp{0}, [x@\tstamp{0}]}, \angled{y:0@\tstamp{0},[y@\tstamp{0}]} \} \\
T1.\Rcur = [x@\tstamp{0}, y@\tstamp{0}] \quad T2.\Rcur = [x@\tstamp{0}, y@\tstamp{0}]
\end{array}
\]
После исполнения двух записей (левым) потоком $T1$, в память попадает два новых сообщения, одно из которых
было сделано высвобождающей записью:
\[
\begin{array}{l}
M = \{
\angled{x:0@\tstamp{0}, [x@\tstamp{0}]}, \angled{y:0@\tstamp{0},[y@\tstamp{0}]}, \\
\qquad \angled{x:1@\tstamp{1}, [x@\tstamp{1}]}, \angled{y:1@\tstamp{1},\graybox{[x@\tstamp{1},y@\tstamp{1}]}}
 \} \\
T1.\Rcur = [x@\tstamp{1}, y@\tstamp{1}] \quad T2.\Rcur = [x@\tstamp{0}, y@\tstamp{0}]
\end{array}
\]
После того, как (правый) поток выполняет приобретающее чтение из сообщения 
$\angled{y:1@\tstamp{1},[x@\tstamp{1},y@\tstamp{1}]}$, его базовый фронт увеличивается по обоим компонентам.
\[
\begin{array}{l}
T2.\Rcur = [\graybox{x@\tstamp{1}}, y@\tstamp{1}]
\end{array}
\]
После этого (правый) поток $T2$ не может прочитать старое сообщение $\angled{x:0@\tstamp{0}, [x@\tstamp{0}]}$.
Таким образом модель $\OpCpp$ запрещает результат $[a = 1, b = 0]$ для программы ${\rm MP\text{-}rel\text{-}acq}$.

\subsection{Операционные буферы}
Тем не менее, не все слабые сценарии поведения программ, наблюдаемые в модели C/C++11, могут быть описаны
приведенными выше механизмами.
Одной из таких является программа ${\rm LB\text{-}rlx}$ (load buffering, буферизация записи):
\begin{equation*}
\tag{LB-rlx}\label{ex:LBrlx}
\begin{tabular}{c}
  $\writeInstParam{\rlx}{x}{0}; \writeInstParam{\rlx}{y}{0};$ \\
\begin{tabular}{L || L}
  \readInstParam{\rlx}{a}{x}; & \readInstParam{\rlx}{b}{y}; \\
  \writeInstParam{\rlx}{y}{1} & \writeInstParam{\rlx}{x}{1} \\
\end{tabular}
\end{tabular}
\end{equation*}
Модель памяти C/C++11 разрешает сценарий поведения этой программы с результатом $[a = 1, b = 1]$.
Такой результат требует, чтобы в момент исполнения инструкции $\readInstParam{\rlx}{a}{x}$
сообщени, соответствующая инструкции $\writeInstParam{\rlx}{x}{1}$, было уже в памяти,
и аналогично для пары инструкций
$\readInstParam{\rlx}{b}{y}$ и $\writeInstParam{\rlx}{y}{1}$.
Таким образом, хотя бы в одном из потоков инструкция записи должна быть исполнена раньше чтения.

Для решения этой проблемы модель $\OpCpp$ добавляет в состояние каждого потока по
\emph{операционному буферу}.
Операционный буфер --- это список записей об отложенных инструкциях, которые 
хранят всю необходимую информацию для дальнейшего их исполнения. 
Так, в частности, когда поток откладывает инструкцию чтения, он заменяет её в программе
на новое, уникальное символьное значение%
\footnote{Семантика $\OpCpp$ задана в стиле редукционных контекстов \cite{Felleisen-Hieb:TCS92,Felleisen-al:BOOK09},
т.е. программа в ней представляется как выражение, которое постепенно редуцируется.
Как следствие, инструкция чтения в этой семантике --- это некоторое подвыражение, которое, будучи вычисленным,
заменяется на прочитанное значение.
Подробное описание семантики в виде редукционных контекстов приведено в разделе \ref{sec:opc11:formal}.
}, а в буфер добавляет пару, состоящую из символьного значения
и целевой локации.
В то время как для отложенной инструкции записи в буфер сохраняется целевая локация и значение,
которое нужно записать.
Далее поток машины $\OpCpp$ может недетерминировано выбрать отложенную инструкцию из буфера и,
если в буфере перед выбранной инструкцией нет инструкции, которая может непосредственно повлиять на результат
выбранной, исполнить её.
Так, данный механизм позволяет в программе ${\rm LB\text{-}rlx}$ отложить исполнение инструкции чтения в левом потоке,
что даёт возможность получить результат $[a = 1, b = 1]$.

\subsection{Спекулятивное исполнение}
Оригинальная модель C/C++11 поддерживает оптимизацию, при которой инструкция, которая
встречается в обоих ветках условного оператора, может быть вынесена за пределы этого
оператора.
Так, в следующей программе инструкция $\writeInstParam{\rlx}{y}{1}$
семантически не зависит от условия $\kw{if}$-оператора, а значит может быть
выполнена перед инструкцией $\readInstParam{\rlx}{a}{x}$.
Это позволяет получить $c = 1$ после выполнения программы.
\begin{equation*}
\tag{SE-simple}
\begin{tabular}{c}
  $\writeInstParam{\rlx}{x}{0}; \writeInstParam{\rlx}{y}{0}; \writeInstParam{\rlx}{z}{0};$ \\
\begin{tabular}{L || L}
  \begin{array}{@{}l@{}}
    \readInstParam{\rlx}{a}{x}; \\
    \iteml{a}{
      \writeInstParam{\rlx}{z}{1}; \\
      \writeInstParam{\rlx}{y}{1}
    }
    {\writeInstParam{\rlx}{y}{1}}
  \end{array} &
  \begin{array}{@{}l@{}}
    \readInstParam{\rlx}{b}{y}; \\
    \iteml{b}{
      \writeInstParam{\rlx}{x}{1}
    }
    {\skipc}
  \end{array}
\end{tabular} \\
  $\readInstParam{\rlx}{c}{z}$
\end{tabular}
\end{equation*}

Для того, чтобы поддержать такие сценарии поведения в $\OpCpp$, операционные буферы могут быть \emph{вложенными}.
Когда исполнение потока подходит к условному оператору, условие которого зависит от ранее отложенной
операции, семантика добавляет в буфер кортеж, который содержит символическое представление условия
и два пустых подбуфера. Эти подбуферы в дальнейшем будут пополняться инструкциями $\kw{then}$ и $\kw{else}$
веток оператора.

Рассмотрим сценарий поведения программы ${\rm SE-simple}$, в котором $c = 1$.
После исполнения инициализирующих инструкций записи память машины $\OpCpp$ содержит три сообщения:
\[
M = \{\angled{x:0@\tstamp{0}, [x@\tstamp{0}]}, \angled{y:0@\tstamp{0},[y@\tstamp{0}]},
      \angled{z:0@\tstamp{0},[z@\tstamp{0}]}\}.
\]
Далее левый поток откладывает выполнение инструкции чтения и начинает спекулятивно исполнять условный оператор.
Так, в буфере левого потока оказывается две записи:
\[\angled{\readInstParam{\rlx}{a}{x}; \kw{if} \; a \; \angled{} \; \angled{}}.\]
Продолжая (спекулятивно) откладывать инструкции, левый поток помешает все инструкции из
условного оператора в соответствующие подбуферы:
\[\angled{\readInstParam{\rlx}{a}{x};
  \kw{if} \; a \; \angled{\writeInstParam{\rlx}{z}{1}; \writeInstParam{\rlx}{y}{1}} \;
  \angled{\writeInstParam{\rlx}{y}{1}}}.\]
После того, как в подбуферах оказываются одинаковые инструкции
(в данном случае, $\writeInstParam{\rlx}{y}{1}$), и перед ними в подбуферах нет
конфликтующих инструкций, модель $\OpCpp$ может вынести их на предыдущей уровень буфера:
\[\angled{\readInstParam{\rlx}{a}{x}; \writeInstParam{\rlx}{y}{1};
  \kw{if} \; a \; \angled{\writeInstParam{\rlx}{z}{1}} \;
  \angled{} }.\]
Далее, поскольку $\readInstParam{\rlx}{a}{x}$ и $\writeInstParam{\rlx}{y}{1}$
независимы, может быть исполнена запись в $y$, после чего в памяти появляется новое сообщение:
\[
\begin{array}{@{}l@{}}
M = \{\angled{x:0@\tstamp{0}, [x@\tstamp{0}]}, \angled{y:0@\tstamp{0},[y@\tstamp{0}]},
      \angled{z:0@\tstamp{0},[z@\tstamp{0}]}, \graybox{\angled{y:1@\tstamp{1},[y@\tstamp{1}]}}\}.
\end{array}
\]
После этого результат $c = 1$ получается следующим образом.
Правый поток читает из нового сообщения, присваивая $1$ в $b$.
Поскольку в правом потоке условие вычисляется к $1$, происходит исполнение записи в $x$:
\[
\begin{array}{@{}l@{}}
M = \{\angled{x:0@\tstamp{0}, [x@\tstamp{0}]}, \angled{y:0@\tstamp{0},[y@\tstamp{0}]}, \angled{z:0@\tstamp{0},[z@\tstamp{0}]}, \\
\qquad \angled{y:1@\tstamp{1},[y@\tstamp{1}]}, \graybox{\angled{x:1@\tstamp{1},[x@\tstamp{1}]}}\}.
\end{array}
\]
После этого, левый поток может выполнить отложенное чтение $\readInstParam{\rlx}{a}{x}$ из добавленного сообщения.
Так, в буфере левого потока остаётся только одна запись, соответствующая отложенной конструкции $\kw{if}$, где
условие было вычислено к $1$:
\[\angled{
  \kw{if} \; 1 \; \angled{\writeInstParam{\rlx}{z}{1}} \;
  \angled{}}.\]
После вычисления отложенной конструкции $\kw{if}$ и выполнения записи в $z$ в памяти находится шесть сообщений:
\[
\begin{array}{@{}l@{}}
M = \{\angled{x:0@\tstamp{0}, [x@\tstamp{0}]}, \angled{y:0@\tstamp{0},[y@\tstamp{0}]}, \angled{z:0@\tstamp{0},[z@\tstamp{0}]}, \\
\qquad \angled{y:1@\tstamp{1},[y@\tstamp{1}]}, \angled{x:1@\tstamp{1},[x@\tstamp{1}]}, \graybox{\angled{z:1@\tstamp{1},[z@\tstamp{1}]}}\}.
\end{array}
\]
Чтение из последней записи в локацию $z$ приводит к результату $c = 1$.

Идея перевода повторяющихся инструкций из вложенных буферов естественным образом обобщается на
случай вложенных условных операторов.

\section{Продвинутые детали модели}
\label{sec:opc11:fullmodel}
В это разделе описывается то, как с помощью фронтов представляется поведение
$\sco$- и $\con$-инструкции, и ищутся гонки по данным на неатомарных обращениях к памяти.
Кроме того, рассматривается проблема соединения потоков (thread's joining) в контексте
оптимизации по секвенциализации потоков (thread's sequentialization).

\subsection{$\sco$-инструкции}
Оригинальная модель C/C++11 гарантирует наличие такого тотального порядка, $\lSC$, на $\sco$-событиях,
который не противоречит программному порядку, $\lPO$, отношению ``синхронизируется с'', $\lSW$,
и порядка памяти, $\lMO$.
Помимо этого, $\sco$-чтения обладает теми же свойствами, как и приобретающие чтения,
а $\sco$-записи --- как высвобождающие записи.

Рассмотрим программу ${\rm SB-sc}$ (store buffering, буферизация записи).
\begin{equation*}
\tag{SB-sc}
\begin{tabular}{c}
  $\writeInstParam{\sco}{x}{0}; \writeInstParam{\sco}{y}{0};$ \\
\begin{tabular}{L || L}
  \writeInstParam{\sco}{x}{1}; & \writeInstParam{\sco}{y}{1} \\
 \readInstParam{\sco}{a}{y};   & \readInstParam{\sco}{b}{x}; \\
\end{tabular}
\end{tabular}
\end{equation*}
Модель C/C++11 запрещает результат $[a = 0, b = 0]$ для неё.
Это объясняется тем, что как минимум одно из чтений находится позже все остальных событий в отношении $\lSC$,
а это значит, что соответствующий поток в момент исполнения этого чтения осведомлён о всех ($\sco$-)записях в программе.

Для того, чтобы гарантировать аналогичное ограничение, в состоянии машины $\OpCpp$ добавляется глобальный
(общий для всех потоков) компонент --- \emph{$\sco$-фронт}, $\Rsc$.
Этот фронт используется следующим образом: при выполнении $\sco$-чтения из локации $\loc$
поток обновляет свой базовый фронт на $[\loc @ \Rsc(\loc)]$, а при выполнении $\sco$-записи
в локацию $\loc$ сообщения с меткой времени $\tau$ поток обновляет $\sco$-фронт на $[\loc@\tau]$.
Таким образом, $\sco$-чтение из локации $\loc$ не может прочитать сообщение в памяти, которое имеет
меньшую метку времени, чем метка сообщения в ту же локацию, которое было записано последней на тот момент $\sco$-записью.

\subsection{Неатомарные обращения}
Согласно модели C/C++11, программы с гонками по данным, в которых участвуют неатомарные обращения к памяти,
обладают неопределенном поведением. Так, рассмотрим следующую программу.
\begin{equation*}
\tag{DR-rlx-na}
\begin{tabular}{c}
  $\writeInstParam{\na}{d}{0};$ \\
\begin{tabular}{L || L}
 \writeInstParam{\rlx}{d}{1};   & \readInstParam{\na}{a}{d}; \\
\end{tabular}
\end{tabular}
\end{equation*}
В ней есть гонка по данным между инструкциями $\writeInstParam{\rlx}{d}{1}$ и $\readInstParam{\na}{a}{d}$.
Мы можем идентифицировать эту гонку с помощью базовых фронтов в случае сценария исполнения, в котором
сначала выполняется запись левым потоком, а потом --- чтение правым.
В такой ситуации правый поток будет выполнять неатомарную операцию над локацией $d$, при этом не
являясь осведомленным о последний записи в данную локацию.
Если модель $\OpCpp$ идентифицировала гонку по данным, в которую вовлечена неатомарная операция,
хотя бы в одном сценарии поведения программы, считается, что программа в целом обладает неопределенным
поведением.

Рассмотрим похожую программу, также с гонкой по данным.
\begin{equation*}
\tag{DR-na-rlx}
\begin{tabular}{c}
  $\writeInstParam{\na}{d}{0};$ \\
\begin{tabular}{L || L}
 \writeInstParam{\na}{d}{1};  & \readInstParam{\rlx}{a}{d}; \\
\end{tabular}
\end{tabular}
\end{equation*}
Идентификация гонки в данном случае не может быть проведена только с помощью базовых фронтов потоков.
Для решения проблемы мы вводим в состояние машины $\OpCpp$ ещё один глобальный фронт --- \emph{$\na$-фронт}, $\Rna$.
Подобно $\sco$-фронту, $\na$-фронт по локации возвращает метку времени последней $\na$-записи в неё.
Так, при выполнении любой операции над локацией $\loc$ поток проверяет, что он осведомлён о последней
$\na$-записи в $\loc$ (т.е. его базовый фронт по $\loc$ больше или равен $\Rna(\loc)$), и если нет, то
машина $\OpCpp$ сигнализирует о гонке.

С помощью такой техники гонка по данным в программе ${\rm DR\text{-}na\text{-}rlx}$ идентифицируется в сценарии
поведения, в котором $\na$-запись левого потока выполняется до $\rlx$-чтения правого потока.

\subsection{Потребляющие чтения}
Потребляющие (consume, $\con$) чтения являются более слабой версией приобретающих чтений.
Так, приобретающее чтение обновляет базовый фронт потока с помощью фронта прочитанного сообщения
и тем самым влияет на все последующие инструкции, тогда как потребляющее чтение действует только
на последующие чтения, которые находятся в зависимости по адресу%
\footnote{Инструкция чтения $i$ \emph{зависит по адресу} от инструкции чтения $j$, если
целевой адрес $i$ зависит от результата исполнения $j$.}
от него.

Рассмотрим программу, в которой используется потребляющее чтение.
\begin{equation*}
\tag{MP-con-na-2}
\begin{tabular}{c}
  $\writeInstParam{\na}{p}{\nullPtr}; \writeInstParam{\na}{d}{0}; \writeInstParam{\na}{x}{0};$ \\
\begin{tabular}{L || L}
  \begin{array}{@{}l@{}}
    \writeInstParam{\rlx}{x}{1}; \\
    \writeInstParam{\na}{d}{1}; \\
    \writeInstParam{\rel}{p}{d} \\
  \end{array}
  &
  \begin{array}{@{}l@{}}
    \readInstParam{\con}{a}{p}; \\
    \iteml{a \neq \nullPtr}
          {\readInstParam{\na}{b}{a}; \\
           \readInstParam{\rlx}{c}{x}}
          {\assignInst{b}{0}; \\ \assignInst{c}{0};}
  \end{array}
\end{tabular}
\end{tabular}
\end{equation*}
В этой программе левый поток передаёт информацию, записанную в локацию $d$, правому потоку через указатель $p$.
Правый поток с помощью $\con$-чтения получает содержимое указателя $p$ в переменную $a$.
Если переменная $a$ не $\nullPtr$, то поток далее читает из той локации, на которую указывает $a$ (в данном случае на локацию $d$),
а потом --- из локации $x$.
У этой программы существует три возможных результата исполнения в модели C/C++11:
$[a = \nullPtr, b = 0, c = 0]$,
$[a = d, b = 1, c = 1]$ и
$[a = d, b = 1, c = 0]$.
Если в программе $\con$-чтение заменить на $\acq$-чтение, то последний результат станет невозможным,
т.к. после выполнения $\readInstParam{\acq}{a}{p}$ с результатом $d$, базовый фронт правого потока будет
указывать на сообщения, которые были получены в результате исполнения $\writeInstParam{\rlx}{x}{1}$ и
$\writeInstParam{\na}{d}{1}$.
В то же время $\con$-чтение $\readInstParam{\con}{a}{p}$ ``синхронизирует'' только последующее чтение $\readInstParam{\na}{b}{a}$,
т.к. оно является разыменованием результата $\con$-чтения, и не влияет на независимое чтение $\readInstParam{\rlx}{c}{x}$.

Для поддержания подобного поведения модель $\OpCpp$ может \emph{аннотировать} с помощью фронтов инструкции чтения, которые зависят
от $\con$-чтений. Когда потребляющее чтение получает из памяти сообщение $\angled{\loc:\val@\tau,\R}$,
оно, вместо того, чтобы обновить базовый фронт потока с помощью $\R$, как это сделало бы приобретающее чтение,
помечает все зависимые от него инструкции чтения фронтом $\R$.
В дальнейшем, когда помеченная инструкция чтения будет исполняться, она скомбинирует базовый фронт потока на тот момент
с фронтом-пометкой для того, чтобы вычислить минимальную метку времени, сообщение с которой доступно для чтения.
Аналогичным образом помечаются и обрабатываются отложенные чтения в операционных буферах, которые ссылаются
на символьный результат $\con$-чтения.

\subsection{Соединение потоков}
\label{sec:opc11:join}
В момент соединения потоков, т.е. когда оба потока закончили своё исполнение,
естественно ожидать, что все отложенные операции были выполнены, и, соответственно,
операционные буферы пусты.
Это подтверждается тем, что в оригинальной модели C/C++11 \cite{Batty-al:POPL11}
используется отношение ``дополнительно синхронизируется с'' (additional-synchronizes-with, $\lASW$),
которое связывает последние событие потока с первой следующей за потоком инструкцией родительского потока.
Отношение $\lASW$ является частью отношения $\lHB$. Это означает, что родительский поток
становится осведомлен о всех тех сообщениях, которые были прочитаны дочерними потоками.
В модели $\OpCpp$ это выражается тем, что соединение потоков возможно, только если их операционные буферы
пусты, а после соединения потоков родительский поток получает базовый фронт,
равный комбинации базовых фронтов соединяемых потоков.

Тем не менее, это противоречит требованию, исходящему от стандартов C и C++11 --- 
оптимизация секвенциализации ($C_1\;||\;C_2 \optarrow C_1;\;C_2$) должна быть корректной.
Это делает предыдущие предположения некорректными.
Данная проблема может быть проиллюстрирована на следующей программе,
в которой параллельная композиция с пустым потоком может быть заменена на
не пустой поток.
\begin{equation*}
\tag{LB-rlx-join}
\begin{tabular}{c}
  $\writeInstParam{\rlx}{x}{0}; \writeInstParam{\rlx}{y}{0};$ \\
\begin{tabular}{L || L || L || L}
  \begin{array}{@{}l@{}}
    \readInstParam{\rlx}{a}{y} \\
  \end{array}
  &
\skipc
  &
  \begin{array}{@{}l@{}}
    \readInstParam{\rlx}{b}{x} \\
  \end{array}
  &
\skipc \\
\multicolumn{2}{c ||}{$\writeInstParam{\rlx}{x}{1}$} &
\multicolumn{2}{c}{$\writeInstParam{\rlx}{y}{1}$}
\end{tabular}
\end{tabular}
\end{equation*}
Если применить такую оптимизацию к одной из композиций потоков,
то результат $[a = 1, b = 1]$ станет возможным.
Для того, чтобы поддержать данный сценарий поведения,
мы допускаем альтернативное правило соединения потоков как отдельный аспект в интерпретаторе модели.

\subsection{Расслабленные обращения и синхронизация}

\section{Формальное определение модели}
\label{sec:opc11:formal}
В разделе приводится математическое определение операционной модели C/C++11.

\section{Интерпретация и тестирование модели}

\subsection{Тестирование алгоритма RCU}

\input{Dissertation/litmusTestsTable}

\begin{figure*}[t]
\input{Dissertation/rcuProg}
\caption[Реализация алгоритма QSBR RCU]
{Реализация алгоритма QSBR RCU.
 При тестировании была рассмотрена также версия без фрагментов, выделенных серым фоном
 (Раздел~\ref{sec:testing}).}
\label{fig:rcuProg}
\end{figure*}

\section{Свойства модели. Выводы}
